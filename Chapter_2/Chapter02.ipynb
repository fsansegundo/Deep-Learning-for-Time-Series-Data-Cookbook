{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwO306SUMP8r"
   },
   "source": [
    "# Chapter 02: Getting Started with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lghveFFjBK9"
   },
   "source": [
    "## Get access to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23280,
     "status": "ok",
     "timestamp": 1748868530998,
     "user": {
      "displayName": "MLMIC MLMIC",
      "userId": "10142984148635638428"
     },
     "user_tz": -120
    },
    "id": "1KP1lwnZh2Qv",
    "outputId": "f8622641-75a2-48ef-bc1f-ae062f009cdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Colab environment not detected. Running in local environment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "use_colab = False\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')        \n",
    "    os.chdir('/content/drive/MyDrive/Colab Notebooks/Deep-Learning-for-Time-Series-Data-Cookbook/Chapter_2')\n",
    "except ImportError:\n",
    "    print(\"Google Colab environment not detected. Running in local environment.\")\n",
    "\n",
    "\n",
    "# if use_colab:\n",
    "#     # If running in Google Colab, mount Google Drive\n",
    "#     try:\n",
    "#         from google.colab import drive\n",
    "#         drive.mount('/content/drive')        \n",
    "#         os.chdir('/content/drive/MyDrive/Colab Notebooks/Deep-Learning-for-Time-Series-Data-Cookbook/Chapter_2')\n",
    "#     except ImportError:\n",
    "#         print(\"Google Colab environment not detected. Running in local environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7R70tSos96g"
   },
   "source": [
    "## Basic operations in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11275,
     "status": "ok",
     "timestamp": 1748868811043,
     "user": {
      "displayName": "MLMIC MLMIC",
      "userId": "10142984148635638428"
     },
     "user_tz": -120
    },
    "id": "vqi3UOzGs8IP"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([[1, 2], [3, 4]])\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_array = np.array([5, 6, 7])\n",
    "t3 = torch.from_numpy(np_array)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.zeros((3, 3))\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.ones((3, 3), dtype=torch.int64)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t6 = torch.eye(3)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6,  8, 10])\n",
      "tensor([4, 4, 4])\n",
      "tensor([ 5, 12, 21])\n",
      "tensor([5.0000, 3.0000, 2.3333])\n"
     ]
    }
   ],
   "source": [
    "result = t1 + t3\n",
    "print(result)\n",
    "result = t3 - t1\n",
    "print(result)\n",
    "result = t1 * t3\n",
    "print(result)\n",
    "result = t3 / t1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.arange(9) # Creates a 1D tensor [0, 1, 2, ..., 8]\n",
    "t8 = t7.reshape((3, 3)) # Reshapes the tensor to a 3x3 matrix\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced operations in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([5, 6, 7])\n",
      "tensor(38)\n"
     ]
    }
   ],
   "source": [
    "print(t1)\n",
    "print(t3)\n",
    "dot_product = torch.dot(t1, t3)\n",
    "print(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "t_transposed = t2.T\n",
    "print(t2)\n",
    "print(t_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([5, 6, 7])\n",
      "tensor([[ 20],\n",
      "        [ 74],\n",
      "        [128]])\n"
     ]
    }
   ],
   "source": [
    "print(t8)\n",
    "print(t3)\n",
    "matrix_product = torch.mm(t8, t3.reshape(3, 1))\n",
    "print(matrix_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor(-2.)\n",
      "tensor([[-2,  1],\n",
      "        [ 1,  0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(t2)\n",
    "det = torch.det(t2.float())\n",
    "print(det)\n",
    "inverse = torch.inverse(t2.float())\n",
    "print(inverse.int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple neural network with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.1682,  0.1341, -1.0243,  0.6603, -1.5947,  2.1601, -0.4789, -0.5081,\n",
       "           0.6440, -0.1328],\n",
       "         [ 1.8440,  0.8277,  1.5968, -0.9206, -0.4501, -0.0243,  0.3353,  0.3317,\n",
       "           0.2594,  0.3663],\n",
       "         [-0.3241,  0.6907,  0.1984, -0.1498,  0.6317, -2.0370,  0.0132, -0.7915,\n",
       "           0.7904, -1.4297],\n",
       "         [-1.1334, -0.4756, -0.0565,  0.0566,  0.2903, -0.6863,  0.8955, -0.1206,\n",
       "          -0.7149, -0.2287],\n",
       "         [-1.0735, -0.5989, -0.7003, -0.2159,  1.2172, -0.7518, -0.9734,  0.3644,\n",
       "          -0.3032, -1.3468]], requires_grad=True),\n",
       " tensor([0., 0., 0., 0., 0.], requires_grad=True),\n",
       " tensor([[ 0.3391,  0.5167, -1.5682,  0.1060,  1.1213]], requires_grad=True),\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.randn(100, 10)  # 100 samples, 10 time steps\n",
    "y = torch.randn(100, 1)\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 5\n",
    "output_size = 1\n",
    "\n",
    "W1 = torch.randn(hidden_size, input_size).requires_grad_()\n",
    "b1 = torch.zeros(hidden_size, requires_grad=True)\n",
    "W2 = torch.randn(output_size, hidden_size).requires_grad_()\n",
    "b2 = torch.zeros(output_size, requires_grad=True)\n",
    "W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def simple_neural_net(x, W1, b1, W2, b2):\n",
    "    z1 = torch.mm(x, W1.t()) + b1\n",
    "    a1 = torch.sigmoid(z1)\n",
    "    z2 = torch.mm(a1, W2.t()) + b2\n",
    "    return z2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Loss: 0.8656741976737976\n",
      "Epoch: 10 \t Loss: 0.8619359135627747\n",
      "Epoch: 20 \t Loss: 0.8583920001983643\n",
      "Epoch: 30 \t Loss: 0.8550294637680054\n",
      "Epoch: 40 \t Loss: 0.8518365025520325\n",
      "Epoch: 50 \t Loss: 0.8488021492958069\n",
      "Epoch: 60 \t Loss: 0.8459166288375854\n",
      "Epoch: 70 \t Loss: 0.8431702256202698\n",
      "Epoch: 80 \t Loss: 0.8405547738075256\n",
      "Epoch: 90 \t Loss: 0.8380621075630188\n",
      "Epoch: 100 \t Loss: 0.835685133934021\n",
      "Epoch: 110 \t Loss: 0.8334167003631592\n",
      "Epoch: 120 \t Loss: 0.8312506079673767\n",
      "Epoch: 130 \t Loss: 0.8291811347007751\n",
      "Epoch: 140 \t Loss: 0.827202558517456\n",
      "Epoch: 150 \t Loss: 0.8253099322319031\n",
      "Epoch: 160 \t Loss: 0.8234984278678894\n",
      "Epoch: 170 \t Loss: 0.8217635750770569\n",
      "Epoch: 180 \t Loss: 0.8201012015342712\n",
      "Epoch: 190 \t Loss: 0.8185076117515564\n",
      "Epoch: 200 \t Loss: 0.8169789910316467\n",
      "Epoch: 210 \t Loss: 0.8155120015144348\n",
      "Epoch: 220 \t Loss: 0.814103364944458\n",
      "Epoch: 230 \t Loss: 0.8127502202987671\n",
      "Epoch: 240 \t Loss: 0.8114497065544128\n",
      "Epoch: 250 \t Loss: 0.8101990818977356\n",
      "Epoch: 260 \t Loss: 0.8089960813522339\n",
      "Epoch: 270 \t Loss: 0.8078381419181824\n",
      "Epoch: 280 \t Loss: 0.8067232370376587\n",
      "Epoch: 290 \t Loss: 0.8056492209434509\n",
      "Epoch: 300 \t Loss: 0.8046141266822815\n",
      "Epoch: 310 \t Loss: 0.8036162257194519\n",
      "Epoch: 320 \t Loss: 0.8026537299156189\n",
      "Epoch: 330 \t Loss: 0.8017247915267944\n",
      "Epoch: 340 \t Loss: 0.8008280992507935\n",
      "Epoch: 350 \t Loss: 0.7999622821807861\n",
      "Epoch: 360 \t Loss: 0.7991257309913635\n",
      "Epoch: 370 \t Loss: 0.7983171939849854\n",
      "Epoch: 380 \t Loss: 0.7975354790687561\n",
      "Epoch: 390 \t Loss: 0.796779453754425\n",
      "Epoch: 400 \t Loss: 0.7960478663444519\n",
      "Epoch: 410 \t Loss: 0.795339822769165\n",
      "Epoch: 420 \t Loss: 0.7946542501449585\n",
      "Epoch: 430 \t Loss: 0.7939901947975159\n",
      "Epoch: 440 \t Loss: 0.7933467030525208\n",
      "Epoch: 450 \t Loss: 0.7927230000495911\n",
      "Epoch: 460 \t Loss: 0.7921183705329895\n",
      "Epoch: 470 \t Loss: 0.7915318012237549\n",
      "Epoch: 480 \t Loss: 0.7909626960754395\n",
      "Epoch: 490 \t Loss: 0.7904103994369507\n",
      "Epoch: 500 \t Loss: 0.7898741960525513\n",
      "Epoch: 510 \t Loss: 0.7893533706665039\n",
      "Epoch: 520 \t Loss: 0.7888475060462952\n",
      "Epoch: 530 \t Loss: 0.7883559465408325\n",
      "Epoch: 540 \t Loss: 0.7878780961036682\n",
      "Epoch: 550 \t Loss: 0.7874134182929993\n",
      "Epoch: 560 \t Loss: 0.7869614958763123\n",
      "Epoch: 570 \t Loss: 0.786521852016449\n",
      "Epoch: 580 \t Loss: 0.786094069480896\n",
      "Epoch: 590 \t Loss: 0.7856776118278503\n",
      "Epoch: 600 \t Loss: 0.7852720618247986\n",
      "Epoch: 610 \t Loss: 0.7848771214485168\n",
      "Epoch: 620 \t Loss: 0.7844923138618469\n",
      "Epoch: 630 \t Loss: 0.7841174006462097\n",
      "Epoch: 640 \t Loss: 0.7837519645690918\n",
      "Epoch: 650 \t Loss: 0.7833955883979797\n",
      "Epoch: 660 \t Loss: 0.7830482125282288\n",
      "Epoch: 670 \t Loss: 0.7827093005180359\n",
      "Epoch: 680 \t Loss: 0.7823786735534668\n",
      "Epoch: 690 \t Loss: 0.7820559740066528\n",
      "Epoch: 700 \t Loss: 0.7817410230636597\n",
      "Epoch: 710 \t Loss: 0.7814335227012634\n",
      "Epoch: 720 \t Loss: 0.7811331748962402\n",
      "Epoch: 730 \t Loss: 0.7808398604393005\n",
      "Epoch: 740 \t Loss: 0.7805532217025757\n",
      "Epoch: 750 \t Loss: 0.7802731990814209\n",
      "Epoch: 760 \t Loss: 0.7799994945526123\n",
      "Epoch: 770 \t Loss: 0.7797319293022156\n",
      "Epoch: 780 \t Loss: 0.7794702649116516\n",
      "Epoch: 790 \t Loss: 0.7792143821716309\n",
      "Epoch: 800 \t Loss: 0.7789640426635742\n",
      "Epoch: 810 \t Loss: 0.7787191867828369\n",
      "Epoch: 820 \t Loss: 0.7784795165061951\n",
      "Epoch: 830 \t Loss: 0.7782449722290039\n",
      "Epoch: 840 \t Loss: 0.7780154347419739\n",
      "Epoch: 850 \t Loss: 0.7777905464172363\n",
      "Epoch: 860 \t Loss: 0.7775704860687256\n",
      "Epoch: 870 \t Loss: 0.7773548364639282\n",
      "Epoch: 880 \t Loss: 0.777143657207489\n",
      "Epoch: 890 \t Loss: 0.7769366502761841\n",
      "Epoch: 900 \t Loss: 0.7767338752746582\n",
      "Epoch: 910 \t Loss: 0.7765350341796875\n",
      "Epoch: 920 \t Loss: 0.7763402462005615\n",
      "Epoch: 930 \t Loss: 0.7761491537094116\n",
      "Epoch: 940 \t Loss: 0.7759619355201721\n",
      "Epoch: 950 \t Loss: 0.7757781744003296\n",
      "Epoch: 960 \t Loss: 0.7755979299545288\n",
      "Epoch: 970 \t Loss: 0.7754212021827698\n",
      "Epoch: 980 \t Loss: 0.7752477526664734\n",
      "Epoch: 990 \t Loss: 0.7750775218009949\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_pred = simple_neural_net(X, W1, b1, W2, b2)\n",
    "    loss = loss_fn(y_pred.squeeze(), y)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        W1 -= lr * W1.grad\n",
    "        b1 -= lr * b1.grad\n",
    "        W2 -= lr * W2.grad\n",
    "        b2 -= lr * b2.grad\n",
    "\n",
    "    W1.grad.zero_()\n",
    "    b1.grad.zero_()\n",
    "    W2.grad.zero_()\n",
    "    b2.grad.zero_()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch} \\t Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a feedforward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 10 input units, 5 units in the hidden layer\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        # 5 units in the hidden layer, 1 output unit\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.226313591003418\n",
      "Epoch 2, Loss: 1.225061058998108\n",
      "Epoch 3, Loss: 1.2238587141036987\n",
      "Epoch 4, Loss: 1.222710371017456\n",
      "Epoch 5, Loss: 1.2215958833694458\n",
      "Epoch 6, Loss: 1.220513105392456\n",
      "Epoch 7, Loss: 1.2194608449935913\n",
      "Epoch 8, Loss: 1.2184460163116455\n",
      "Epoch 9, Loss: 1.2174689769744873\n",
      "Epoch 10, Loss: 1.2165169715881348\n",
      "Epoch 11, Loss: 1.2155828475952148\n",
      "Epoch 12, Loss: 1.2146645784378052\n",
      "Epoch 13, Loss: 1.2137675285339355\n",
      "Epoch 14, Loss: 1.2128901481628418\n",
      "Epoch 15, Loss: 1.212031602859497\n",
      "Epoch 16, Loss: 1.2111910581588745\n",
      "Epoch 17, Loss: 1.2103673219680786\n",
      "Epoch 18, Loss: 1.209559679031372\n",
      "Epoch 19, Loss: 1.208767294883728\n",
      "Epoch 20, Loss: 1.2079905271530151\n",
      "Epoch 21, Loss: 1.2072335481643677\n",
      "Epoch 22, Loss: 1.2065165042877197\n",
      "Epoch 23, Loss: 1.2058480978012085\n",
      "Epoch 24, Loss: 1.2051907777786255\n",
      "Epoch 25, Loss: 1.204564094543457\n",
      "Epoch 26, Loss: 1.2039451599121094\n",
      "Epoch 27, Loss: 1.2033350467681885\n",
      "Epoch 28, Loss: 1.2027395963668823\n",
      "Epoch 29, Loss: 1.202195644378662\n",
      "Epoch 30, Loss: 1.201658844947815\n",
      "Epoch 31, Loss: 1.2011293172836304\n",
      "Epoch 32, Loss: 1.2006062269210815\n",
      "Epoch 33, Loss: 1.2000895738601685\n",
      "Epoch 34, Loss: 1.1995810270309448\n",
      "Epoch 35, Loss: 1.199076771736145\n",
      "Epoch 36, Loss: 1.1985774040222168\n",
      "Epoch 37, Loss: 1.1980834007263184\n",
      "Epoch 38, Loss: 1.197607159614563\n",
      "Epoch 39, Loss: 1.1971352100372314\n",
      "Epoch 40, Loss: 1.1966681480407715\n",
      "Epoch 41, Loss: 1.196205735206604\n",
      "Epoch 42, Loss: 1.195748209953308\n",
      "Epoch 43, Loss: 1.1952966451644897\n",
      "Epoch 44, Loss: 1.1948485374450684\n",
      "Epoch 45, Loss: 1.194403052330017\n",
      "Epoch 46, Loss: 1.1939605474472046\n",
      "Epoch 47, Loss: 1.1935218572616577\n",
      "Epoch 48, Loss: 1.1930863857269287\n",
      "Epoch 49, Loss: 1.1926524639129639\n",
      "Epoch 50, Loss: 1.1922177076339722\n",
      "Epoch 51, Loss: 1.1918096542358398\n",
      "Epoch 52, Loss: 1.1914061307907104\n",
      "Epoch 53, Loss: 1.191004753112793\n",
      "Epoch 54, Loss: 1.1906086206436157\n",
      "Epoch 55, Loss: 1.1902164220809937\n",
      "Epoch 56, Loss: 1.189810037612915\n",
      "Epoch 57, Loss: 1.1893593072891235\n",
      "Epoch 58, Loss: 1.1889114379882812\n",
      "Epoch 59, Loss: 1.1884657144546509\n",
      "Epoch 60, Loss: 1.1880238056182861\n",
      "Epoch 61, Loss: 1.1875866651535034\n",
      "Epoch 62, Loss: 1.187131404876709\n",
      "Epoch 63, Loss: 1.1866765022277832\n",
      "Epoch 64, Loss: 1.186224102973938\n",
      "Epoch 65, Loss: 1.185777187347412\n",
      "Epoch 66, Loss: 1.18533456325531\n",
      "Epoch 67, Loss: 1.1848959922790527\n",
      "Epoch 68, Loss: 1.184464454650879\n",
      "Epoch 69, Loss: 1.1840245723724365\n",
      "Epoch 70, Loss: 1.1836003065109253\n",
      "Epoch 71, Loss: 1.1831670999526978\n",
      "Epoch 72, Loss: 1.1827409267425537\n",
      "Epoch 73, Loss: 1.1823197603225708\n",
      "Epoch 74, Loss: 1.1818913221359253\n",
      "Epoch 75, Loss: 1.1814686059951782\n",
      "Epoch 76, Loss: 1.1810482740402222\n",
      "Epoch 77, Loss: 1.1806381940841675\n",
      "Epoch 78, Loss: 1.1802101135253906\n",
      "Epoch 79, Loss: 1.1797950267791748\n",
      "Epoch 80, Loss: 1.179389238357544\n",
      "Epoch 81, Loss: 1.1789706945419312\n",
      "Epoch 82, Loss: 1.178551197052002\n",
      "Epoch 83, Loss: 1.1781344413757324\n",
      "Epoch 84, Loss: 1.177716851234436\n",
      "Epoch 85, Loss: 1.177302360534668\n",
      "Epoch 86, Loss: 1.176892876625061\n",
      "Epoch 87, Loss: 1.1764789819717407\n",
      "Epoch 88, Loss: 1.1760680675506592\n",
      "Epoch 89, Loss: 1.1756658554077148\n",
      "Epoch 90, Loss: 1.175258755683899\n",
      "Epoch 91, Loss: 1.1748552322387695\n",
      "Epoch 92, Loss: 1.174452304840088\n",
      "Epoch 93, Loss: 1.1740483045578003\n",
      "Epoch 94, Loss: 1.173641324043274\n",
      "Epoch 95, Loss: 1.1732468605041504\n",
      "Epoch 96, Loss: 1.172875165939331\n",
      "Epoch 97, Loss: 1.1725114583969116\n",
      "Epoch 98, Loss: 1.1721028089523315\n",
      "Epoch 99, Loss: 1.1717041730880737\n",
      "Epoch 100, Loss: 1.1713000535964966\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a synthetic dataset\n",
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(100, 1)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Forward pass: compute predicted outputs by passing\n",
    "    # inputs to the model\n",
    "    output = net(X)\n",
    "    # Compute loss\n",
    "    loss = loss_fn(output, Y)\n",
    "    # Zero the gradients before running the backward pass\n",
    "    optimizer.zero_grad()\n",
    "    # Backward pass: compute gradient of the loss\n",
    "    # with respect to model parameters\n",
    "    loss.backward()\n",
    "    # Calling the step function on an Optimizer performs\n",
    "    # an update on its parameters\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(10, 20, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # initial hidden state\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)  # get RNN output\n",
    "        # pass last output to Fully Connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "rnn = RNN(10, 20, 1)  # 10 features, 20 hidden units, 1 output\n",
    "print(rnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4021955728530884\n",
      "Epoch 2, Loss: 1.3857455253601074\n",
      "Epoch 3, Loss: 1.3703455924987793\n",
      "Epoch 4, Loss: 1.355907917022705\n",
      "Epoch 5, Loss: 1.3423523902893066\n",
      "Epoch 6, Loss: 1.3296074867248535\n",
      "Epoch 7, Loss: 1.3176078796386719\n",
      "Epoch 8, Loss: 1.3062944412231445\n",
      "Epoch 9, Loss: 1.295613408088684\n",
      "Epoch 10, Loss: 1.2855157852172852\n",
      "Epoch 11, Loss: 1.2759569883346558\n",
      "Epoch 12, Loss: 1.2668962478637695\n",
      "Epoch 13, Loss: 1.258296251296997\n",
      "Epoch 14, Loss: 1.2501230239868164\n",
      "Epoch 15, Loss: 1.2423454523086548\n",
      "Epoch 16, Loss: 1.2349345684051514\n",
      "Epoch 17, Loss: 1.227864146232605\n",
      "Epoch 18, Loss: 1.2211103439331055\n",
      "Epoch 19, Loss: 1.2146506309509277\n",
      "Epoch 20, Loss: 1.208464503288269\n",
      "Epoch 21, Loss: 1.2025333642959595\n",
      "Epoch 22, Loss: 1.1968398094177246\n",
      "Epoch 23, Loss: 1.1913676261901855\n",
      "Epoch 24, Loss: 1.1861023902893066\n",
      "Epoch 25, Loss: 1.1810301542282104\n",
      "Epoch 26, Loss: 1.1761384010314941\n",
      "Epoch 27, Loss: 1.1714156866073608\n",
      "Epoch 28, Loss: 1.1668509244918823\n",
      "Epoch 29, Loss: 1.1624345779418945\n",
      "Epoch 30, Loss: 1.1581569910049438\n",
      "Epoch 31, Loss: 1.1540098190307617\n",
      "Epoch 32, Loss: 1.1499853134155273\n",
      "Epoch 33, Loss: 1.146075963973999\n",
      "Epoch 34, Loss: 1.1422752141952515\n",
      "Epoch 35, Loss: 1.1385765075683594\n",
      "Epoch 36, Loss: 1.1349741220474243\n",
      "Epoch 37, Loss: 1.1314626932144165\n",
      "Epoch 38, Loss: 1.1280369758605957\n",
      "Epoch 39, Loss: 1.1246925592422485\n",
      "Epoch 40, Loss: 1.1214251518249512\n",
      "Epoch 41, Loss: 1.1182304620742798\n",
      "Epoch 42, Loss: 1.1151050329208374\n",
      "Epoch 43, Loss: 1.1120449304580688\n",
      "Epoch 44, Loss: 1.1090471744537354\n",
      "Epoch 45, Loss: 1.1061087846755981\n",
      "Epoch 46, Loss: 1.103226900100708\n",
      "Epoch 47, Loss: 1.1003988981246948\n",
      "Epoch 48, Loss: 1.097622275352478\n",
      "Epoch 49, Loss: 1.094894528388977\n",
      "Epoch 50, Loss: 1.0922138690948486\n",
      "Epoch 51, Loss: 1.0895781517028809\n",
      "Epoch 52, Loss: 1.086985468864441\n",
      "Epoch 53, Loss: 1.0844340324401855\n",
      "Epoch 54, Loss: 1.0819224119186401\n",
      "Epoch 55, Loss: 1.0794485807418823\n",
      "Epoch 56, Loss: 1.0770115852355957\n",
      "Epoch 57, Loss: 1.0746098756790161\n",
      "Epoch 58, Loss: 1.072242021560669\n",
      "Epoch 59, Loss: 1.0699069499969482\n",
      "Epoch 60, Loss: 1.0676037073135376\n",
      "Epoch 61, Loss: 1.065330982208252\n",
      "Epoch 62, Loss: 1.0630875825881958\n",
      "Epoch 63, Loss: 1.060873031616211\n",
      "Epoch 64, Loss: 1.0586860179901123\n",
      "Epoch 65, Loss: 1.0565258264541626\n",
      "Epoch 66, Loss: 1.0543917417526245\n",
      "Epoch 67, Loss: 1.0522828102111816\n",
      "Epoch 68, Loss: 1.0501983165740967\n",
      "Epoch 69, Loss: 1.0481376647949219\n",
      "Epoch 70, Loss: 1.0461002588272095\n",
      "Epoch 71, Loss: 1.0440850257873535\n",
      "Epoch 72, Loss: 1.042091965675354\n",
      "Epoch 73, Loss: 1.0401201248168945\n",
      "Epoch 74, Loss: 1.0381689071655273\n",
      "Epoch 75, Loss: 1.0362380743026733\n",
      "Epoch 76, Loss: 1.0343267917633057\n",
      "Epoch 77, Loss: 1.0324345827102661\n",
      "Epoch 78, Loss: 1.0305613279342651\n",
      "Epoch 79, Loss: 1.0287061929702759\n",
      "Epoch 80, Loss: 1.0268689393997192\n",
      "Epoch 81, Loss: 1.025049090385437\n",
      "Epoch 82, Loss: 1.023246169090271\n",
      "Epoch 83, Loss: 1.021459937095642\n",
      "Epoch 84, Loss: 1.019689917564392\n",
      "Epoch 85, Loss: 1.0179355144500732\n",
      "Epoch 86, Loss: 1.0161967277526855\n",
      "Epoch 87, Loss: 1.0144730806350708\n",
      "Epoch 88, Loss: 1.01276433467865\n",
      "Epoch 89, Loss: 1.0110697746276855\n",
      "Epoch 90, Loss: 1.0093895196914673\n",
      "Epoch 91, Loss: 1.0077232122421265\n",
      "Epoch 92, Loss: 1.0060701370239258\n",
      "Epoch 93, Loss: 1.0044304132461548\n",
      "Epoch 94, Loss: 1.0028036832809448\n",
      "Epoch 95, Loss: 1.0011895895004272\n",
      "Epoch 96, Loss: 0.9995877146720886\n",
      "Epoch 97, Loss: 0.9979981184005737\n",
      "Epoch 98, Loss: 0.9964204430580139\n",
      "Epoch 99, Loss: 0.9948539733886719\n",
      "Epoch 100, Loss: 0.993299126625061\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Modify the synthetic dataset for RNN\n",
    "\n",
    "X = torch.randn(100, 5, 10)  # 100 samples, 5 time steps, 10 features\n",
    "Y = torch.randn(100, 1)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    output = rnn(X)\n",
    "    loss = loss_fn(output, Y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MLMIC25fc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
